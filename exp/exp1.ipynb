{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "399f2116",
   "metadata": {},
   "source": [
    "# JSON-RPC Basics\n",
    "### **Request** Structure\n",
    "```json\n",
    "{\n",
    "    \"jsonrpc\": \"2.0\",\n",
    "    \"id\": 1,\n",
    "    \"method\": \"some.method\",\n",
    "    \"params\":{...}\n",
    "}\n",
    "```\n",
    "\n",
    "### **Response** Structure\n",
    "*Success*\n",
    "```json\n",
    "{\n",
    "    \"jsonrpc\": \"2.0\",\n",
    "    \"id\":1,\n",
    "    \"result\": {...}\n",
    "}\n",
    "```\n",
    "*Failure*\n",
    "```json\n",
    "{\n",
    "    \"jsonrpc\": \"2.0\",\n",
    "    \"id\": 1,\n",
    "    \"error\": {\n",
    "        \"code\": 123,\n",
    "        \"message\": \"Something broke\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "### Fields\n",
    "**Required**\n",
    "| Field              | Meaning                                    |\n",
    "| ------------------ | ------------------------------------------ |\n",
    "| `\"jsonrpc\": \"2.0\"` | Must always be exactly `\"2.0\"`             |\n",
    "| `\"method\"`         | The name of the API method                 |\n",
    "| `\"id\"`             | A unique request ID (any type except null) |\n",
    "\n",
    "**Optional**\n",
    "| Field      | Meaning                                  |\n",
    "| ---------- | ---------------------------------------- |\n",
    "| `\"params\"` | Arguments to the method (object or list) |\n",
    "\n",
    "### Batch Requests\n",
    "```json\n",
    "[\n",
    "  { \"jsonrpc\": \"2.0\", \"id\": 1, \"method\": \"math.add\", \"params\": [1,2] },\n",
    "  { \"jsonrpc\": \"2.0\", \"id\": 2, \"method\": \"math.mul\", \"params\": [3,4] }\n",
    "]\n",
    "```\n",
    "\n",
    "### Notifications\n",
    "when you send a request without `id`, it becomes a notification or request without response\n",
    "```json\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"method\": \"metrics/ping\"\n",
    "}\n",
    "```\n",
    "Used for events like \"didOpen\", \"statusChanged\" etc. MCP uses these for server→client updates.\n",
    "\n",
    "### JSON-RPC over different transports\n",
    "**Over HTTP**:  \n",
    "you `post` the JSON to a URL  \n",
    "  \n",
    "**Over WebSockets/TCP**:  \n",
    "Just send the JSON message as strings  \n",
    "  \n",
    "**Over SSE (for MCP)**:  \n",
    "- Client connects to `/sse`\n",
    "- Server sents messages as SSE events\n",
    "- Client writes the JSON-RPC messages over the *write channel* (usually HTTP POST or WebSocket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aeade791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                COMMAND                  CREATED         STATUS         PORTS                                         NAMES\n",
      "81d7804abdf6   docker/mcp-gateway   \"/docker-mcp gateway…\"   8 seconds ago   Up 7 seconds   0.0.0.0:8811->8811/tcp, [::]:8811->8811/tcp   docker_mcp_host-gateway-1\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7984f710",
   "metadata": {},
   "source": [
    "# Important\n",
    "MCP needs to carry out an **Initialization Phase**\n",
    "1. Client sends initilization request\n",
    "2. Server sends a response\n",
    "3. Client needs to notify the server\n",
    "\n",
    "Takaways:\n",
    "1. Initialize the client with these headers:\n",
    "    ```json\n",
    "    {\n",
    "        \"Mcp-Protocol-Version\": \"2024-11-05\",\n",
    "        \"Accept\": \"application/json, text/event-stream\",\n",
    "    }\n",
    "    ```\n",
    "2. You need the *same async client* for the *same request sequence* or you would need to begin a new **Initialization Phase**\n",
    "3. When the server responds you need to get the **mcp-session-id**\n",
    "4. Subsequent requests needs the extra header: `headers={\"Mcp-Session-Id\": mcp-session-id}`\n",
    "5. Since, `--transport=streaming`, MPC server return SSE or `f\"data: {some_data}\\n\\n\"`. So return `response.text` and parse the sse output\n",
    "\n",
    "### Error codes:\n",
    "PARSE_ERROR = -32700  \n",
    "INVALID_REQUEST = -32600  \n",
    "METHOD_NOT_FOUND = -32601  \n",
    "INVALID_PARAMS = -32602  \n",
    "INTERNAL_ERROR = -32603  \n",
    "\n",
    "### Initialization jRPC request:\n",
    "```python\n",
    "payload = {\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"id\": 1,\n",
    "        \"method\": \"initialize\",\n",
    "        \"params\": {\n",
    "            \"protocolVersion\": \"2024-11-05\",\n",
    "            \"capabilities\": {},\n",
    "            \"clientInfo\": {\n",
    "                \"name\": \"test-client\",\n",
    "                \"version\": \"1.0.0\",\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "```\n",
    "### Notification jRPC request:\n",
    "It will not recieve any response from the server\n",
    "```python\n",
    "payload = {\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"method\": \"notifications/initialized\",\n",
    "    }\n",
    "```\n",
    "### Tool List jRPC request:\n",
    "```python\n",
    "payload = {\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"id\": 2,\n",
    "        \"method\": \"tools/list\",\n",
    "        \"params\": {},\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2250c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot run this on ipynb\n",
    "import httpx\n",
    "import json\n",
    "import asyncio\n",
    "\n",
    "server_url = \"http://localhost:8811/mcp\"\n",
    "\n",
    "def parse_sse_response(response_text: str):\n",
    "    lines = response_text.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        if line.startswith(\"data: \"):\n",
    "            data = line[6:]\n",
    "            try:\n",
    "                return json.loads(data)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Could not parse JSON: {data}\")\n",
    "    return None\n",
    "\n",
    "async def initialize_session(client: httpx.AsyncClient):\n",
    "    payload = {\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"id\": 1,\n",
    "        \"method\": \"initialize\",\n",
    "        \"params\": {\n",
    "            \"protocolVersion\": \"2024-11-05\",\n",
    "            \"capabilities\": {},\n",
    "            \"clientInfo\": {\n",
    "                \"name\": \"test-client\",\n",
    "                \"version\": \"1.0.0\",\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    resp = await client.post(server_url, json=payload)\n",
    "    resp.raise_for_status()\n",
    "    session_id = resp.headers.get(\"Mcp-Session-Id\") or resp.headers.get(\"mcp-session-id\")\n",
    "    print(\"Initialize response headers:\")\n",
    "    print(dict(resp.headers))\n",
    "    print(\"Mcp-Session-Id:\", session_id) # Get this session for subsequent request\n",
    "\n",
    "    return resp.text, session_id\n",
    "\n",
    "async def send_initialized_notification(client: httpx.AsyncClient, session_id: str):\n",
    "    payload = {\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"method\": \"notifications/initialized\",\n",
    "    }\n",
    "\n",
    "    resp = await client.post(\n",
    "        server_url,\n",
    "        json=payload,\n",
    "        headers={\"Mcp-Session-Id\": session_id}, # Adding the session id as a header\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    return resp.text\n",
    "\n",
    "async def get_tools_list(client: httpx.AsyncClient, session_id: str):\n",
    "    payload = {\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"id\": 2,\n",
    "        \"method\": \"tools/list\",\n",
    "        \"params\": {},\n",
    "    }\n",
    "\n",
    "    resp = await client.post(\n",
    "        server_url,\n",
    "        json=payload,\n",
    "        headers={\"Mcp-Session-Id\": session_id}, # Adding the session id as a header\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    return resp.text\n",
    "\n",
    "async def main():\n",
    "    try:\n",
    "        async with httpx.AsyncClient(\n",
    "            timeout=300,\n",
    "            headers={\n",
    "                # Need this headers\n",
    "                \"Mcp-Protocol-Version\": \"2024-11-05\",\n",
    "                \"Accept\": \"application/json, text/event-stream\",\n",
    "            },\n",
    "            limits=httpx.Limits(max_keepalive_connections=1, max_connections=1),\n",
    "        ) as client:\n",
    "            print(\"Initializing session...\")\n",
    "            init_response, session_id = await initialize_session(client)\n",
    "            print(\"Initialization response:\")\n",
    "            print(init_response)\n",
    "\n",
    "            init_data = parse_sse_response(init_response)\n",
    "            if init_data and \"result\" in init_data:\n",
    "                print(\"\\n===PARSED INITIALIZATION===\")\n",
    "                print(json.dumps(init_data[\"result\"], indent=2))\n",
    "\n",
    "            print(\"\\nSending initialized notification...\")\n",
    "            notif_response = await send_initialized_notification(client, session_id)\n",
    "            print(\"Notification response:\")\n",
    "            # repr prints all the characters like '\\n' etc. Here the response will usually be '' since notification jRPC does not have a response\n",
    "            print(repr(notif_response))\n",
    "\n",
    "            print(\"\\nGetting tools list...\")\n",
    "            tools_response = await get_tools_list(client, session_id)\n",
    "            print(\"Tools list raw response:\")\n",
    "            print(tools_response)\n",
    "\n",
    "            tools_data = parse_sse_response(tools_response)\n",
    "            if tools_data:\n",
    "                print(\"\\n===PARSED TOOLS LIST===\")\n",
    "                print(json.dumps(tools_data, indent=2))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f6a08",
   "metadata": {},
   "source": [
    "# Output:\n",
    "```python\n",
    "# tools list output -> List[Dict[str, Any]]\n",
    "# Typically:\n",
    "tools = [{\n",
    "  \"description\": \"...\",\n",
    "  \"inputSchema\": {\n",
    "    \"properties\": {...}\n",
    "  },\n",
    "  \"name\": \"...\"\n",
    "  \"outputSchema\": {...},\n",
    "}]\n",
    "```\n",
    "### Example\n",
    "```json\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 2,\n",
    "  \"result\": {\n",
    "    \"tools\": [\n",
    "      {\n",
    "        \"_meta\": {\n",
    "          \"_fastmcp\": {\n",
    "            \"tags\": []\n",
    "          }\n",
    "        },\n",
    "        \"description\": \"Extract key facts from a Wikipedia article, optionally focused on a topic.\",\n",
    "        \"inputSchema\": {\n",
    "          \"properties\": {\n",
    "            \"count\": {\n",
    "              \"default\": 5,\n",
    "              \"type\": \"integer\"\n",
    "            },\n",
    "            \"title\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"topic_within_article\": {\n",
    "              \"default\": \"\",\n",
    "              \"type\": \"string\"\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\n",
    "            \"title\"\n",
    "          ],\n",
    "          \"type\": \"object\"\n",
    "        },\n",
    "        \"name\": \"extract_key_facts\",\n",
    "        \"outputSchema\": {\n",
    "          \"additionalProperties\": true,\n",
    "          \"type\": \"object\"\n",
    "        }\n",
    "      },\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c2a67c",
   "metadata": {},
   "source": [
    "### Trial with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "171b28a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import httpx\n",
    "import asyncio\n",
    "import json\n",
    "import copy\n",
    "from typing import Optional, List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_API_URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "MCP_PROTOCOL_VERSION = \"2024-11-05\"\n",
    "MCP_URL = \"http://localhost:8811/mcp\"\n",
    "\n",
    "def parse_sse_json(response_text: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Given an SSE response like:\n",
    "        event: message\n",
    "        id: ...\n",
    "        data: {...JSON...}\n",
    "\n",
    "    extract and return the JSON object from the first 'data: ' line.\n",
    "    \"\"\"\n",
    "    for line in response_text.splitlines():\n",
    "        if line.startswith(\"data: \"):\n",
    "            data = line[6:]\n",
    "            try:\n",
    "                return json.loads(data)\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Could not parse JSON from SSE data:\", data)\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "class MCPGatewayClient:\n",
    "    def __init__(self):\n",
    "        self.gateway_url = MCP_URL\n",
    "        self.session_id:Optional[str]=None\n",
    "        self._next_id = 1\n",
    "\n",
    "    async def initialize(self, client: httpx.AsyncClient):\n",
    "        payload = {\n",
    "            \"jsonrpc\": \"2.0\",\n",
    "            \"id\": self._next_id,\n",
    "            \"method\": \"initialize\",\n",
    "            \"params\": {\n",
    "                \"protocolVersion\": MCP_PROTOCOL_VERSION,\n",
    "                \"capabilities\": {},\n",
    "                \"clientInfo\": {\n",
    "                    \"name\": \"gpt-mcp-bridge\",\n",
    "                    \"version\": \"1.0.0\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        self._next_id+=1\n",
    "        response = await client.post(\n",
    "            url=self.gateway_url,\n",
    "            json=payload,\n",
    "            headers={\n",
    "                \"Mcp-Protocol-Version\": MCP_PROTOCOL_VERSION,\n",
    "                \"Accept\": \"application/json, text/event-stream\",\n",
    "            }\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        self.session_id = response.headers.get(\"Mcp-Session-Id\") or response.headers.get(\"mcp-session-id\")\n",
    "        data = parse_sse_json(response.text)\n",
    "        if not data:\n",
    "            raise RuntimeError(f\"Invalid initialize response: {response.text}\")\n",
    "        \n",
    "        notif_payload = {\n",
    "            \"jsonrpc\": \"2.0\",\n",
    "            \"method\": \"notifications/initialized\",\n",
    "        }\n",
    "        notif_headers = {\n",
    "            \"Mcp-Session-Id\": self.session_id,\n",
    "            \"Mcp-Protocol-Version\": MCP_PROTOCOL_VERSION,\n",
    "            \"Accept\": \"application/json, text/event-stream\",\n",
    "        }\n",
    "        notif_response = await client.post(\n",
    "            url=self.gateway_url,\n",
    "            json=notif_payload,\n",
    "            headers=notif_headers\n",
    "        )\n",
    "        notif_response.raise_for_status()\n",
    "\n",
    "        return data\n",
    "    \n",
    "    async def list_tools(self, client: httpx.AsyncClient):\n",
    "        payload = {\n",
    "            \"jsonrpc\": \"2.0\",\n",
    "            \"id\": self._next_id,\n",
    "            \"method\": \"tools/list\",\n",
    "            \"params\": {}\n",
    "        }\n",
    "        self._next_id+=1\n",
    "        headers = {\n",
    "            \"Mcp-Session-Id\": self.session_id,\n",
    "            \"Mcp-Protocol-Version\": MCP_PROTOCOL_VERSION,\n",
    "            \"Accept\": \"application/json, text/event-stream\",\n",
    "        }\n",
    "        response = await client.post(\n",
    "            url=self.gateway_url,\n",
    "            json=payload,\n",
    "            headers=headers\n",
    "        )\n",
    "        data = parse_sse_json(response.text)\n",
    "        if \"error\" in data:\n",
    "            raise RuntimeError(f\"MCP tools/list error: {data['error']}\")\n",
    "        \n",
    "        return data['result']['tools']\n",
    "    \n",
    "    async def call_tool(self, client:httpx.AsyncClient, name:str, arguments: Dict[str, Any]):\n",
    "        payload ={\n",
    "            \"jsonrpc\": \"2.0\",\n",
    "            \"id\": self._next_id,\n",
    "            \"method\": \"tools/call\",\n",
    "            \"params\": {\n",
    "                \"name\": name,\n",
    "                \"arguments\": arguments\n",
    "            }\n",
    "        }\n",
    "        self._next_id+=1\n",
    "        headers = {\n",
    "            \"Mcp-Session-Id\": self.session_id,\n",
    "            \"Mcp-Protocol-Version\": MCP_PROTOCOL_VERSION,\n",
    "            \"Accept\": \"application/json, text/event-stream\",\n",
    "        }\n",
    "\n",
    "        response = await client.post(\n",
    "            url=self.gateway_url,\n",
    "            json=payload,\n",
    "            headers=headers\n",
    "        )\n",
    "        data = parse_sse_json(response.text)\n",
    "        if 'error' in data:\n",
    "            raise RuntimeError(f\"MCP tools/call error: {data['error']}\")\n",
    "        \n",
    "        return data[\"result\"]\n",
    "    \n",
    "def tool_schema_conversion(mcp_tools: List[Dict[str, Any]]):\n",
    "    \"\"\"\n",
    "    Convert MCP tool definitions to OpenAI function tools.\n",
    "    \"\"\"\n",
    "    tools: List[Dict[str, Any]] = []\n",
    "    for t in mcp_tools:\n",
    "        name = t.get('name')\n",
    "        if not name:\n",
    "            continue\n",
    "\n",
    "        description = t.get(\"description\", \"\")\n",
    "        input_schema = copy.deepcopy(t.get(\"inputSchema\", {})) or {}\n",
    "\n",
    "        if input_schema.get('type') is None:\n",
    "            input_schema['type'] = \"object\"\n",
    "        if \"properties\" not in input_schema:\n",
    "            input_schema[\"properties\"] = {}\n",
    "        input_schema.setdefault(\"additionalProperties\", False)\n",
    "        \n",
    "        tools.append(\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": { \n",
    "                    \"name\": name,\n",
    "                    \"description\": description,\n",
    "                    \"parameters\": input_schema,\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    return tools\n",
    "\n",
    "\n",
    "async def gpt_with_mcp(user_message: str, max_iterations:int=5):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "    - initialize MCP\n",
    "    - list tools\n",
    "    - send user + tools to gpt\n",
    "    - handle a round of tool calls via mcp\n",
    "    - return final assitant answer\n",
    "    \"\"\"\n",
    "    mcp = MCPGatewayClient()\n",
    "    async with httpx.AsyncClient(timeout=300) as client:\n",
    "        await mcp.initialize(client)\n",
    "        mcp_tools = await mcp.list_tools(client)\n",
    "        openai_tools = tool_schema_conversion(mcp_tools)\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant with access to Wikipedia via tools. Use tools when the user asks about factual topics.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_message\n",
    "            }\n",
    "        ]\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "\n",
    "        #Set max itirations of tool calls\n",
    "        for i in range(max_iterations):\n",
    "            payload = {\n",
    "                \"model\": \"gpt-4o-mini\",\n",
    "                \"messages\": messages,\n",
    "                \"tools\": openai_tools,\n",
    "                \"tool_choice\": \"auto\",\n",
    "            }\n",
    "            response = await client.post(\n",
    "                OPENAI_API_URL,\n",
    "                headers=headers,\n",
    "                json=payload\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            assistant_message = data['choices'][0]['message']\n",
    "            finish_reason = data['choices'][0]['finish_reason']\n",
    "            messages.append(assistant_message)\n",
    "            \n",
    "            if finish_reason == 'stop':\n",
    "                return {\n",
    "                    \"content\": assistant_message.get('content'),\n",
    "                    \"full_response\": data\n",
    "                }\n",
    "            \n",
    "            if finish_reason == 'tool_calls' and assistant_message.get('tool_calls'):\n",
    "                tool_calls = assistant_message['tool_calls']\n",
    "                print(f\"\\n===== Iteration {i} ===== Processing {len(tool_calls)} tool calls====\")\n",
    "                for tc in tool_calls:\n",
    "                    tool_name = tc['function']['name']\n",
    "                    tool_args = json.loads(tc['function']['arguments'])\n",
    "                    tool_call_id = tc['id']\n",
    "\n",
    "                    #Calling tool\n",
    "                    try:\n",
    "                        tool_result = await mcp.call_tool(client=client, name=tool_name, arguments=tool_args)\n",
    "                        if isinstance(tool_result, dict) and 'content' in tool_result:\n",
    "                            content_items = tool_result['content']\n",
    "                            text_parts = []\n",
    "                            for item in content_items:\n",
    "                                if item.get('type') == \"text\" and 'text' in item:\n",
    "                                    text_parts.append(item['text'])\n",
    "\n",
    "                            result_text = \"\\n\".join(text_parts)\n",
    "                        else:\n",
    "                            result_text = json.dumps(tool_result)\n",
    "\n",
    "                        print(f\"Tool Result Preview: {result_text[:200]}...\")\n",
    "\n",
    "                        messages.append({\n",
    "                            \"role\": \"tool\",\n",
    "                            \"tool_call_id\": tool_call_id,\n",
    "                            \"content\": result_text\n",
    "                        })\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error calling tool: {tool_name}: {str(e)}\")\n",
    "                        messages.append({\n",
    "                            \"role\": \"tool\",\n",
    "                            \"tool_call_id\": tool_call_id,\n",
    "                            \"content\": f\"Error: {str(e)}\"\n",
    "                        })\n",
    "\n",
    "                    continue\n",
    "\n",
    "            print(f\"Unexpected finish_reason: {finish_reason}\")\n",
    "            break\n",
    "\n",
    "        return {\n",
    "            \"content\": \"Maximum iterations reached\",\n",
    "            \"messages\": messages,\n",
    "            \"full_response\": data\n",
    "        }\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     async def _test():\n",
    "#         answer = await gpt_with_mcp(\n",
    "#             user_message= \"Who is Alan Turing? Use wikipedia if helpful\", max_iterations=3\n",
    "#         )\n",
    "#         print(\"\\n====Answer====\\n\")\n",
    "#         print(answer['messages'][-1]['content'])\n",
    "\n",
    "#     asyncio.run(_test())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02802045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import LLM_TOOL_SCHEMAS\n",
    "from typing import List, Dict, Any\n",
    "def tool_schema_conversion(mcp_tools: List[Dict[str, Any]], mode: str='default'):\n",
    "    \"\"\"\n",
    "    Convert MCP tool definitions to OpenAI function tools\n",
    "    Now handles dynamic MCP tools (mcp-find, mcp-add, mcp-remove) and code-mode\n",
    "    \"\"\"    \n",
    "    tools: List[Dict[str, Any]] = []\n",
    "\n",
    "    dynamic_tools = {'mcp-find'}\n",
    "    code_mode_tools = {'code-mode', 'mcp-exec'}\n",
    "    exposed_tools = dynamic_tools | code_mode_tools\n",
    "\n",
    "    for t in mcp_tools:\n",
    "        name = t.get('name')\n",
    "        if not name:\n",
    "            continue\n",
    "\n",
    "        if mode == \"default\":\n",
    "            # In default mode, exclude all dynamic tools\n",
    "            if name in exposed_tools:\n",
    "                continue\n",
    "        elif mode in [\"dynamic\", \"code\"]:\n",
    "            # In dynamic and code modes, only expose specific tools\n",
    "            if name not in exposed_tools:\n",
    "                continue\n",
    "\n",
    "        description = t.get(\"description\", \"\")\n",
    "        \n",
    "        # Use clean schemas for LLM-exposed tools\n",
    "        if name in LLM_TOOL_SCHEMAS:\n",
    "            input_schema = copy.deepcopy(LLM_TOOL_SCHEMAS[name])\n",
    "        else:\n",
    "            # For other tools, use original schema with fixes\n",
    "            input_schema = copy.deepcopy(t.get(\"inputSchema\", {})) or {}\n",
    "            \n",
    "            if input_schema.get('type') is None:\n",
    "                input_schema['type'] = 'object'\n",
    "            if 'properties' not in input_schema:\n",
    "                input_schema['properties'] = {}\n",
    "            input_schema.setdefault(\"additionalProperties\", False)\n",
    "            \n",
    "            #input_schema = fix_openai_schema(input_schema)\n",
    "\n",
    "        tools.append(\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": { \n",
    "                    \"name\": name,\n",
    "                    \"description\": description,\n",
    "                    \"parameters\": input_schema,\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    return tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8c602fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_mode = [{\n",
    "      \"description\":\"Create a JavaScript-enabled tool that combines multiple MCP server tools. \\nThis allows you to write scripts that call multiple tools and combine their results.\\nUse the mcp-find tool to find servers and make sure they are are ready with the mcp-add tool. When running\\nmcp-add, we don't have to activate the tools.\\n\",\n",
    "      \"inputSchema\":{\n",
    "         \"type\":\"object\",\n",
    "         \"required\":[\n",
    "            \"servers\",\n",
    "            \"name\"\n",
    "         ],\n",
    "         \"properties\":{\n",
    "            \"name\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"Name for the new code-mode tool (will be prefixed with 'code-mode-')\"\n",
    "            },\n",
    "            \"servers\":{\n",
    "               \"type\":\"array\",\n",
    "               \"description\":\"List of MCP server names whose tools should be available in the JavaScript environment\",\n",
    "               \"items\":{\n",
    "                  \"type\":\"string\"\n",
    "               }\n",
    "            }\n",
    "         }\n",
    "      },\n",
    "      \"name\":\"code-mode\"\n",
    "   }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2625411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = tool_schema_conversion(code_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfb66e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3159be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docker-mcp-host (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
